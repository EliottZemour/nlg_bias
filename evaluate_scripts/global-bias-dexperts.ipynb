{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from prettytable import PrettyTable\n",
    "import operator\n",
    "from colorama import Fore, Back, Style\n",
    "from utils import avg_diff, get_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bias mitigation experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mDEXPERTS_GPT2_MED_ANTIONLY_TEMP1_ALPHA1\u001b[0m\n",
      "+--------------------------------+-----------------------------------------+----------+---------+----------+---------+----------------+\n",
      "|             Domain             |                  Model                  | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------------------+-----------------------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2-medium_gender       | dexperts_gpt2_med_antionly_temp1_alpha1 |  0.0023  |  0.0011 |  0.0032  |  0.0022 |     0.0014     |\n",
      "|        gpt2-medium_race        | dexperts_gpt2_med_antionly_temp1_alpha1 |  0.0199  |  0.007  |  0.0263  |  0.0177 |     0.0008     |\n",
      "| gpt2-medium_religious_ideology | dexperts_gpt2_med_antionly_temp1_alpha1 |  0.0789  |  0.0335 |  0.1237  |  0.0787 |     0.0433     |\n",
      "+--------------------------------+-----------------------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mDEXPERTS_GPT2_MED_ANTI_BASE_TEMP1_ALPHA1\u001b[0m\n",
      "+--------------------------------+------------------------------------------+----------+---------+----------+---------+----------------+\n",
      "|             Domain             |                  Model                   | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------------------+------------------------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2-medium_gender       | dexperts_gpt2_med_anti_base_temp1_alpha1 |  0.0105  |  0.0122 |  0.0028  |  0.0085 |     0.0009     |\n",
      "|        gpt2-medium_race        | dexperts_gpt2_med_anti_base_temp1_alpha1 |  0.0124  |  0.0139 |  0.0261  |  0.0175 |     0.0003     |\n",
      "| gpt2-medium_religious_ideology | dexperts_gpt2_med_anti_base_temp1_alpha1 |  0.0383  |  0.086  |  0.1073  |  0.0772 |     0.022      |\n",
      "+--------------------------------+------------------------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# directories = [\n",
    "#     # 'results/new_temperature/gpt2-medium/',\n",
    "#     # 'results/new_temperature/trigger-gpt2-medium/',\n",
    "#     'results/new_temperature/dexperts-medium/dexperts_gpt2_med_temp1_alpha1/',\n",
    "#     'results/new_temperature/dexperts-medium/dexperts_gpt2_med_antionly_temp1_alpha1/',\n",
    "#     'results/new_temperature/dexperts-medium/dexperts_gpt2_med_anti_base_temp1_alpha2/',\n",
    "# ]\n",
    "\n",
    "directories = [\n",
    "    # 'results/new_temperature/gpt2-medium/',\n",
    "    # 'results/new_temperature/trigger-gpt2-medium/',\n",
    "    # 'results/new_temperature/dexperts-base/dexperts_gpt2_med_temp1_alpha1/',\n",
    "    'results/new_temperature/dexperts-medium/dexperts_gpt2_med_antionly_temp1_alpha1/',\n",
    "    'results/new_temperature/dexperts-medium/dexperts_gpt2_med_anti_base_temp1_alpha1/',\n",
    "]\n",
    "tables = []\n",
    "for score_dir in directories:\n",
    "    score_dir = os.path.join(score_dir, 'score/')\n",
    "    undesired_subgroups = ['Asian_Americans', 'Hispanic_and_Latino_Americans', 'hinduism', 'buddhism', 'sikhism', 'atheism']\n",
    "    table, scores = get_results(score_dir, undesired_subgroups)\n",
    "    tables.append(table)\n",
    "    print(f\"{Fore.LIGHTRED_EX}{score_dir.split('/')[-3].upper()}{Style.RESET_ALL}\")\n",
    "    print(table.get_string(sort_key=operator.itemgetter(1, 0), sortby=\"Domain\"), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Domain</th>\n",
       "            <th>Model</th>\n",
       "            <th>Positive</th>\n",
       "            <th>Neutral</th>\n",
       "            <th>Negative</th>\n",
       "            <th>Average</th>\n",
       "            <th>Toxicity Ratio</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>gpt2-medium_race</td>\n",
       "            <td>dexperts_gpt2_med_antionly_temp1_alpha1</td>\n",
       "            <td>0.0199</td>\n",
       "            <td>0.007</td>\n",
       "            <td>0.0263</td>\n",
       "            <td>0.0177</td>\n",
       "            <td>0.0008</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>gpt2-medium_gender</td>\n",
       "            <td>dexperts_gpt2_med_antionly_temp1_alpha1</td>\n",
       "            <td>0.0023</td>\n",
       "            <td>0.0011</td>\n",
       "            <td>0.0032</td>\n",
       "            <td>0.0022</td>\n",
       "            <td>0.0014</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>gpt2-medium_religious_ideology</td>\n",
       "            <td>dexperts_gpt2_med_antionly_temp1_alpha1</td>\n",
       "            <td>0.0789</td>\n",
       "            <td>0.0335</td>\n",
       "            <td>0.1237</td>\n",
       "            <td>0.0787</td>\n",
       "            <td>0.0433</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+--------------------------------+-----------------------------------------+----------+---------+----------+---------+----------------+\n",
       "|             Domain             |                  Model                  | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
       "+--------------------------------+-----------------------------------------+----------+---------+----------+---------+----------------+\n",
       "|        gpt2-medium_race        | dexperts_gpt2_med_antionly_temp1_alpha1 |  0.0199  |  0.007  |  0.0263  |  0.0177 |     0.0008     |\n",
       "|       gpt2-medium_gender       | dexperts_gpt2_med_antionly_temp1_alpha1 |  0.0023  |  0.0011 |  0.0032  |  0.0022 |     0.0014     |\n",
       "| gpt2-medium_religious_ideology | dexperts_gpt2_med_antionly_temp1_alpha1 |  0.0789  |  0.0335 |  0.1237  |  0.0787 |     0.0433     |\n",
       "+--------------------------------+-----------------------------------------+----------+---------+----------+---------+----------------+"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Domain</th>\n",
       "            <th>Model</th>\n",
       "            <th>Positive</th>\n",
       "            <th>Neutral</th>\n",
       "            <th>Negative</th>\n",
       "            <th>Average</th>\n",
       "            <th>Toxicity Ratio</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>gpt2-medium_race</td>\n",
       "            <td>dexperts_gpt2_med_anti_base_temp1_alpha1</td>\n",
       "            <td>0.0124</td>\n",
       "            <td>0.0139</td>\n",
       "            <td>0.0261</td>\n",
       "            <td>0.0175</td>\n",
       "            <td>0.0003</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>gpt2-medium_gender</td>\n",
       "            <td>dexperts_gpt2_med_anti_base_temp1_alpha1</td>\n",
       "            <td>0.0105</td>\n",
       "            <td>0.0122</td>\n",
       "            <td>0.0028</td>\n",
       "            <td>0.0085</td>\n",
       "            <td>0.0009</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>gpt2-medium_religious_ideology</td>\n",
       "            <td>dexperts_gpt2_med_anti_base_temp1_alpha1</td>\n",
       "            <td>0.0383</td>\n",
       "            <td>0.086</td>\n",
       "            <td>0.1073</td>\n",
       "            <td>0.0772</td>\n",
       "            <td>0.022</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+--------------------------------+------------------------------------------+----------+---------+----------+---------+----------------+\n",
       "|             Domain             |                  Model                   | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
       "+--------------------------------+------------------------------------------+----------+---------+----------+---------+----------------+\n",
       "|        gpt2-medium_race        | dexperts_gpt2_med_anti_base_temp1_alpha1 |  0.0124  |  0.0139 |  0.0261  |  0.0175 |     0.0003     |\n",
       "|       gpt2-medium_gender       | dexperts_gpt2_med_anti_base_temp1_alpha1 |  0.0105  |  0.0122 |  0.0028  |  0.0085 |     0.0009     |\n",
       "| gpt2-medium_religious_ideology | dexperts_gpt2_med_anti_base_temp1_alpha1 |  0.0383  |  0.086  |  0.1073  |  0.0772 |     0.022      |\n",
       "+--------------------------------+------------------------------------------+----------+---------+----------+---------+----------------+"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specialized experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mDEXPERTS_GPT2_MED_GENDER_ALPHA1\u001b[0m\n",
      "+--------------------------------+---------------------------------+----------+---------+----------+---------+----------------+\n",
      "|             Domain             |              Model              | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------------------+---------------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2-medium_gender       | dexperts_gpt2_med_gender_alpha1 |  0.026   |  0.0297 |  0.0065  |  0.0207 |     0.0031     |\n",
      "|        gpt2-medium_race        | dexperts_gpt2_med_gender_alpha1 |  0.0274  |  0.0008 |  0.0257  |  0.018  |     0.0022     |\n",
      "| gpt2-medium_religious_ideology | dexperts_gpt2_med_gender_alpha1 |  0.0772  |  0.0245 |  0.1257  |  0.0758 |     0.0661     |\n",
      "+--------------------------------+---------------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mDEXPERTS_GPT2_MED_RACE_ALPHA1\u001b[0m\n",
      "+--------------------------------+-------------------------------+----------+---------+----------+---------+----------------+\n",
      "|             Domain             |             Model             | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------------------+-------------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2-medium_gender       | dexperts_gpt2_med_race_alpha1 |  0.0147  |  0.0214 |  0.0063  |  0.0141 |     0.0013     |\n",
      "|        gpt2-medium_race        | dexperts_gpt2_med_race_alpha1 |  0.0242  |  0.0014 |  0.0252  |  0.0169 |     0.0003     |\n",
      "| gpt2-medium_religious_ideology | dexperts_gpt2_med_race_alpha1 |  0.0417  |  0.029  |  0.0933  |  0.0546 |     0.0551     |\n",
      "+--------------------------------+-------------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mDEXPERTS_GPT2_MED_RELIGION_ALPHA1\u001b[0m\n",
      "+--------------------------------+-----------------------------------+----------+---------+----------+---------+----------------+\n",
      "|             Domain             |               Model               | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------------------+-----------------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2-medium_gender       | dexperts_gpt2_med_religion_alpha1 |  0.0264  |  0.0325 |  0.0061  |  0.0217 |     0.0007     |\n",
      "|        gpt2-medium_race        | dexperts_gpt2_med_religion_alpha1 |  0.0288  |  0.0078 |  0.0214  |  0.0193 |     0.0009     |\n",
      "| gpt2-medium_religious_ideology | dexperts_gpt2_med_religion_alpha1 |  0.0645  |  0.0561 |  0.1278  |  0.0828 |     0.0068     |\n",
      "+--------------------------------+-----------------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "directories = [\n",
    "    # 'results/new_temperature/gpt2-medium/',\n",
    "    # 'results/new_temperature/trigger-gpt2-medium/',\n",
    "    'results/new_temperature/dexperts-medium/dexperts_gpt2_med_gender_alpha1/',\n",
    "    'results/new_temperature/dexperts-medium/dexperts_gpt2_med_race_alpha1/',\n",
    "    'results/new_temperature/dexperts-medium/dexperts_gpt2_med_religion_alpha1/',\n",
    "]\n",
    "tables = []\n",
    "for score_dir in directories:\n",
    "    score_dir = os.path.join(score_dir, 'score/')\n",
    "    undesired_subgroups = ['Asian_Americans', 'Hispanic_and_Latino_Americans', 'hinduism', 'buddhism', 'sikhism', 'atheism']\n",
    "    table, scores = get_results(score_dir, undesired_subgroups)\n",
    "    tables.append(table)\n",
    "    print(f\"{Fore.LIGHTRED_EX}{score_dir.split('/')[-3].upper()}{Style.RESET_ALL}\")\n",
    "    print(table.get_string(sort_key=operator.itemgetter(1, 0), sortby=\"Domain\"), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Domain</th>\n",
       "            <th>Model</th>\n",
       "            <th>Positive</th>\n",
       "            <th>Neutral</th>\n",
       "            <th>Negative</th>\n",
       "            <th>Average</th>\n",
       "            <th>Toxicity Ratio</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>gpt2-medium_race</td>\n",
       "            <td>dexperts_gpt2_med_religion_alpha1</td>\n",
       "            <td>0.0288</td>\n",
       "            <td>0.0078</td>\n",
       "            <td>0.0214</td>\n",
       "            <td>0.0193</td>\n",
       "            <td>0.0009</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>gpt2-medium_gender</td>\n",
       "            <td>dexperts_gpt2_med_religion_alpha1</td>\n",
       "            <td>0.0264</td>\n",
       "            <td>0.0325</td>\n",
       "            <td>0.0061</td>\n",
       "            <td>0.0217</td>\n",
       "            <td>0.0007</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>gpt2-medium_religious_ideology</td>\n",
       "            <td>dexperts_gpt2_med_religion_alpha1</td>\n",
       "            <td>0.0645</td>\n",
       "            <td>0.0561</td>\n",
       "            <td>0.1278</td>\n",
       "            <td>0.0828</td>\n",
       "            <td>0.0068</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+--------------------------------+-----------------------------------+----------+---------+----------+---------+----------------+\n",
       "|             Domain             |               Model               | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
       "+--------------------------------+-----------------------------------+----------+---------+----------+---------+----------------+\n",
       "|        gpt2-medium_race        | dexperts_gpt2_med_religion_alpha1 |  0.0288  |  0.0078 |  0.0214  |  0.0193 |     0.0009     |\n",
       "|       gpt2-medium_gender       | dexperts_gpt2_med_religion_alpha1 |  0.0264  |  0.0325 |  0.0061  |  0.0217 |     0.0007     |\n",
       "| gpt2-medium_religious_ideology | dexperts_gpt2_med_religion_alpha1 |  0.0645  |  0.0561 |  0.1278  |  0.0828 |     0.0068     |\n",
       "+--------------------------------+-----------------------------------+----------+---------+----------+---------+----------------+"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alpha experiments: dexperts base full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mDEXPERTS_GPT2_TEMP1_ALPHA05\u001b[0m\n",
      "+-------------------------+-----------------------------+----------+---------+----------+---------+----------------+\n",
      "|          Domain         |            Model            | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+-------------------------+-----------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2_gender       | dexperts_gpt2_temp1_alpha05 |  0.0035  |  0.0126 |  0.0079  |  0.008  |     0.0026     |\n",
      "|        gpt2_race        | dexperts_gpt2_temp1_alpha05 |  0.0231  |  0.0027 |  0.026   |  0.0173 |     0.0021     |\n",
      "| gpt2_religious_ideology | dexperts_gpt2_temp1_alpha05 |  0.0483  |  0.0235 |  0.1008  |  0.0575 |     0.042      |\n",
      "+-------------------------+-----------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mDEXPERTS_GPT2_TEMP1_ALPHA1\u001b[0m\n",
      "+-------------------------+----------------------------+----------+---------+----------+---------+----------------+\n",
      "|          Domain         |           Model            | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+-------------------------+----------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2_gender       | dexperts_gpt2_temp1_alpha1 |  0.0082  |  0.0176 |  0.0101  |  0.012  |     0.0026     |\n",
      "|        gpt2_race        | dexperts_gpt2_temp1_alpha1 |  0.0234  |  0.004  |  0.0266  |  0.018  |     0.0008     |\n",
      "| gpt2_religious_ideology | dexperts_gpt2_temp1_alpha1 |  0.024   |  0.047  |  0.0557  |  0.0422 |     0.042      |\n",
      "+-------------------------+----------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mDEXPERTS_GPT2_TEMP1_ALPHA2\u001b[0m\n",
      "+-------------------------+----------------------------+----------+---------+----------+---------+----------------+\n",
      "|          Domain         |           Model            | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+-------------------------+----------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2_gender       | dexperts_gpt2_temp1_alpha2 |  0.0047  |  0.0158 |  0.012   |  0.0108 |     0.0003     |\n",
      "|        gpt2_race        | dexperts_gpt2_temp1_alpha2 |  0.0185  |  0.0044 |  0.022   |  0.015  |     0.0014     |\n",
      "| gpt2_religious_ideology | dexperts_gpt2_temp1_alpha2 |  0.0371  |  0.0386 |  0.0323  |  0.036  |     0.1061     |\n",
      "+-------------------------+----------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "directories = [\n",
    "    # 'results/new_temperature/gpt2/',\n",
    "    'results/new_temperature/dexperts_gpt2_temp1_alpha05/',\n",
    "    'results/new_temperature/dexperts_gpt2_temp1_alpha1/',\n",
    "    'results/new_temperature/dexperts_gpt2_temp1_alpha2/',\n",
    "]\n",
    "tables = []\n",
    "for score_dir in directories:\n",
    "    score_dir = os.path.join(score_dir, 'score/')\n",
    "    undesired_subgroups = ['Asian_Americans', 'Hispanic_and_Latino_Americans', 'hinduism', 'buddhism', 'sikhism', 'atheism']\n",
    "    table, scores = get_results(score_dir, undesired_subgroups)\n",
    "    tables.append(table)\n",
    "    print(f\"{Fore.LIGHTRED_EX}{score_dir.split('/')[-3].upper()}{Style.RESET_ALL}\")\n",
    "    print(table.get_string(sort_key=operator.itemgetter(1, 0), sortby=\"Domain\"), '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alpha experiments: dexperts base antionly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mDEXPERTS_GPT2_ANTIONLY_TEMP1_ALPHA05\u001b[0m\n",
      "+-------------------------+--------------------------------------+----------+---------+----------+---------+----------------+\n",
      "|          Domain         |                Model                 | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+-------------------------+--------------------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2_gender       | dexperts_gpt2_antionly_temp1_alpha05 |  0.0011  |  0.0108 |  0.0119  |  0.0079 |     0.0017     |\n",
      "|        gpt2_race        | dexperts_gpt2_antionly_temp1_alpha05 |  0.0152  |  0.009  |  0.0245  |  0.0162 |     0.0002     |\n",
      "| gpt2_religious_ideology | dexperts_gpt2_antionly_temp1_alpha05 |  0.0554  |  0.0573 |  0.1121  |  0.075  |     0.0329     |\n",
      "+-------------------------+--------------------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mDEXPERTS_GPT2_ANTIONLY_TEMP1_ALPHA1\u001b[0m\n",
      "+-------------------------+-------------------------------------+----------+---------+----------+---------+----------------+\n",
      "|          Domain         |                Model                | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+-------------------------+-------------------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2_gender       | dexperts_gpt2_antionly_temp1_alpha1 |  0.0021  |  0.0116 |  0.0081  |  0.0073 |     0.0011     |\n",
      "|        gpt2_race        | dexperts_gpt2_antionly_temp1_alpha1 |  0.0036  |  0.0123 |  0.0168  |  0.0109 |     0.0006     |\n",
      "| gpt2_religious_ideology | dexperts_gpt2_antionly_temp1_alpha1 |  0.0454  |  0.0673 |  0.1008  |  0.0712 |     0.0335     |\n",
      "+-------------------------+-------------------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mDEXPERTS_GPT2_ANTIONLY_TEMP1_ALPHA2\u001b[0m\n",
      "+-------------------------+-------------------------------------+----------+---------+----------+---------+----------------+\n",
      "|          Domain         |                Model                | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+-------------------------+-------------------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2_gender       | dexperts_gpt2_antionly_temp1_alpha2 |  0.0173  |  0.0097 |  0.0106  |  0.0125 |     0.0005     |\n",
      "|        gpt2_race        | dexperts_gpt2_antionly_temp1_alpha2 |  0.0051  |  0.0103 |  0.0208  |  0.0121 |     0.0004     |\n",
      "| gpt2_religious_ideology | dexperts_gpt2_antionly_temp1_alpha2 |  0.0462  |  0.0647 |  0.078   |  0.063  |     0.0342     |\n",
      "+-------------------------+-------------------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "directories = [\n",
    "    # 'results/new_temperature/gpt2/',\n",
    "    'results/new_temperature/dexperts_gpt2_antionly_temp1_alpha05/',\n",
    "    'results/new_temperature/dexperts_gpt2_antionly_temp1_alpha1/',\n",
    "    'results/new_temperature/dexperts_gpt2_antionly_temp1_alpha2/',\n",
    "]\n",
    "tables = []\n",
    "for score_dir in directories:\n",
    "    score_dir = os.path.join(score_dir, 'score/')\n",
    "    undesired_subgroups = ['Asian_Americans', 'Hispanic_and_Latino_Americans', 'hinduism', 'buddhism', 'sikhism', 'atheism']\n",
    "    table, scores = get_results(score_dir, undesired_subgroups)\n",
    "    tables.append(table)\n",
    "    print(f\"{Fore.LIGHTRED_EX}{score_dir.split('/')[-3].upper()}{Style.RESET_ALL}\")\n",
    "    print(table.get_string(sort_key=operator.itemgetter(1, 0), sortby=\"Domain\"), '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### antionly (2 alphas and base gpt2 as expert): dexperts medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mDEXPERTS_GPT2_MED_ANTIONLY_TEMP1_ALPHA1\u001b[0m\n",
      "+--------------------------------+-----------------------------------------+----------+---------+----------+---------+----------------+\n",
      "|             Domain             |                  Model                  | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------------------+-----------------------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2-medium_gender       | dexperts_gpt2_med_antionly_temp1_alpha1 |  0.0023  |  0.0011 |  0.0032  |  0.0022 |     0.0014     |\n",
      "|        gpt2-medium_race        | dexperts_gpt2_med_antionly_temp1_alpha1 |  0.0199  |  0.007  |  0.0263  |  0.0177 |     0.0008     |\n",
      "| gpt2-medium_religious_ideology | dexperts_gpt2_med_antionly_temp1_alpha1 |  0.0789  |  0.0335 |  0.1237  |  0.0787 |     0.0433     |\n",
      "+--------------------------------+-----------------------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mDEXPERTS_GPT2_MED_ANTIONLY_TEMP1_ALPHA2\u001b[0m\n",
      "+--------------------------------+-----------------------------------------+----------+---------+----------+---------+----------------+\n",
      "|             Domain             |                  Model                  | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------------------+-----------------------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2-medium_gender       | dexperts_gpt2_med_antionly_temp1_alpha2 |  0.0185  |  0.0237 |  0.0031  |  0.0151 |     0.0012     |\n",
      "|        gpt2-medium_race        | dexperts_gpt2_med_antionly_temp1_alpha2 |  0.0225  |  0.0039 |   0.02   |  0.0155 |     0.0023     |\n",
      "| gpt2-medium_religious_ideology | dexperts_gpt2_med_antionly_temp1_alpha2 |  0.0672  |  0.0467 |  0.0825  |  0.0655 |     0.063      |\n",
      "+--------------------------------+-----------------------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mDEXPERTS_GPT2_MED_ANTI_BASE_TEMP1_ALPHA1\u001b[0m\n",
      "+--------------------------------+------------------------------------------+----------+---------+----------+---------+----------------+\n",
      "|             Domain             |                  Model                   | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------------------+------------------------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2-medium_gender       | dexperts_gpt2_med_anti_base_temp1_alpha1 |  0.0105  |  0.0122 |  0.0028  |  0.0085 |     0.0009     |\n",
      "|        gpt2-medium_race        | dexperts_gpt2_med_anti_base_temp1_alpha1 |  0.0124  |  0.0139 |  0.0261  |  0.0175 |     0.0003     |\n",
      "| gpt2-medium_religious_ideology | dexperts_gpt2_med_anti_base_temp1_alpha1 |  0.0383  |  0.086  |  0.1073  |  0.0772 |     0.022      |\n",
      "+--------------------------------+------------------------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mDEXPERTS_GPT2_MED_ANTI_BASE_TEMP1_ALPHA2\u001b[0m\n",
      "+--------------------------------+------------------------------------------+----------+---------+----------+---------+----------------+\n",
      "|             Domain             |                  Model                   | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------------------+------------------------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2-medium_gender       | dexperts_gpt2_med_anti_base_temp1_alpha2 |  0.0041  |  0.0121 |  0.0052  |  0.0071 |     0.0006     |\n",
      "|        gpt2-medium_race        | dexperts_gpt2_med_anti_base_temp1_alpha2 |  0.0128  |  0.0062 |  0.0207  |  0.0132 |     0.0005     |\n",
      "| gpt2-medium_religious_ideology | dexperts_gpt2_med_anti_base_temp1_alpha2 |  0.0973  |  0.0507 |  0.1013  |  0.0831 |     0.0369     |\n",
      "+--------------------------------+------------------------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "directories = [\n",
    "    'results/new_temperature/dexperts_gpt2_med_antionly_temp1_alpha1/',\n",
    "    'results/new_temperature/dexperts_gpt2_med_antionly_temp1_alpha2/',\n",
    "    'results/new_temperature/dexperts_gpt2_med_anti_base_temp1_alpha1/',\n",
    "    'results/new_temperature/dexperts_gpt2_med_anti_base_temp1_alpha2/',\n",
    "]\n",
    "tables = []\n",
    "for score_dir in directories:\n",
    "    score_dir = os.path.join(score_dir, 'score/')\n",
    "    undesired_subgroups = ['Asian_Americans', 'Hispanic_and_Latino_Americans', 'hinduism', 'buddhism', 'sikhism', 'atheism']\n",
    "    table, scores = get_results(score_dir, undesired_subgroups)\n",
    "    tables.append(table)\n",
    "    print(f\"{Fore.LIGHTRED_EX}{score_dir.split('/')[-3].upper()}{Style.RESET_ALL}\")\n",
    "    print(table.get_string(sort_key=operator.itemgetter(1, 0), sortby=\"Domain\"), '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### specialized experts: gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mDEXPERTS_GPT2_GENDER_ALPHA1\u001b[0m\n",
      "+-------------------------+-----------------------------+----------+---------+----------+---------+----------------+\n",
      "|          Domain         |            Model            | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+-------------------------+-----------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2_gender       | dexperts_gpt2_gender_alpha1 |  0.004   |  0.0114 |  0.0036  |  0.0063 |     0.0023     |\n",
      "|        gpt2_race        | dexperts_gpt2_gender_alpha1 |  0.0269  |  0.0009 |  0.0276  |  0.0185 |     0.0011     |\n",
      "| gpt2_religious_ideology | dexperts_gpt2_gender_alpha1 |  0.0315  |  0.0715 |  0.1197  |  0.0742 |     0.0231     |\n",
      "+-------------------------+-----------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mDEXPERTS_GPT2_MED_GENDER_ALPHA1\u001b[0m\n",
      "+--------------------------------+---------------------------------+----------+---------+----------+---------+----------------+\n",
      "|             Domain             |              Model              | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------------------+---------------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2-medium_gender       | dexperts_gpt2_med_gender_alpha1 |  0.0118  |  0.0205 |  0.004   |  0.0121 |     0.0006     |\n",
      "|        gpt2-medium_race        | dexperts_gpt2_med_gender_alpha1 |  0.0362  |  0.0091 |  0.0266  |  0.024  |     0.0006     |\n",
      "| gpt2-medium_religious_ideology | dexperts_gpt2_med_gender_alpha1 |  0.0674  |  0.0447 |  0.1241  |  0.0787 |     0.0637     |\n",
      "+--------------------------------+---------------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "directories = [\n",
    "    'results/new_temperature/dexperts_gpt2_gender_alpha1/',\n",
    "    'results/new_temperature/dexperts_gpt2_med_gender_alpha1/',\n",
    "]\n",
    "\n",
    "tables = []\n",
    "for score_dir in directories:\n",
    "    score_dir = os.path.join(score_dir, 'score/')\n",
    "    undesired_subgroups = ['Asian_Americans', 'Hispanic_and_Latino_Americans', 'hinduism', 'buddhism', 'sikhism', 'atheism']\n",
    "    table, scores = get_results(score_dir, undesired_subgroups)\n",
    "    tables.append(table)\n",
    "    print(f\"{Fore.LIGHTRED_EX}{score_dir.split('/')[-3].upper()}{Style.RESET_ALL}\")\n",
    "    print(table.get_string(sort_key=operator.itemgetter(1, 0), sortby=\"Domain\"), '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### specialized experts: race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mDEXPERTS_GPT2_RACE_ALPHA1\u001b[0m\n",
      "+-------------------------+---------------------------+----------+---------+----------+---------+----------------+\n",
      "|          Domain         |           Model           | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+-------------------------+---------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2_gender       | dexperts_gpt2_race_alpha1 |  0.0075  |  0.011  |  0.0029  |  0.0071 |     0.0007     |\n",
      "|        gpt2_race        | dexperts_gpt2_race_alpha1 |  0.0161  |  0.0018 |  0.0168  |  0.0116 |     0.0005     |\n",
      "| gpt2_religious_ideology | dexperts_gpt2_race_alpha1 |  0.0587  |  0.032  |  0.1163  |  0.069  |     0.0241     |\n",
      "+-------------------------+---------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mDEXPERTS_GPT2_MED_RACE_ALPHA1\u001b[0m\n",
      "+--------------------------------+-------------------------------+----------+---------+----------+---------+----------------+\n",
      "|             Domain             |             Model             | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------------------+-------------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2-medium_gender       | dexperts_gpt2_med_race_alpha1 |  0.016   |  0.0241 |  0.0039  |  0.0147 |     0.0008     |\n",
      "|        gpt2-medium_race        | dexperts_gpt2_med_race_alpha1 |  0.0138  |  0.0001 |  0.0178  |  0.0106 |     0.0006     |\n",
      "| gpt2-medium_religious_ideology | dexperts_gpt2_med_race_alpha1 |  0.0734  |  0.0499 |  0.1233  |  0.0822 |     0.0397     |\n",
      "+--------------------------------+-------------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "directories = [\n",
    "    'results/new_temperature/dexperts_gpt2_race_alpha1/',\n",
    "    'results/new_temperature/dexperts_gpt2_med_race_alpha1/',\n",
    "]\n",
    "\n",
    "tables = []\n",
    "for score_dir in directories:\n",
    "    score_dir = os.path.join(score_dir, 'score/')\n",
    "    undesired_subgroups = ['Asian_Americans', 'Hispanic_and_Latino_Americans', 'hinduism', 'buddhism', 'sikhism', 'atheism']\n",
    "    table, scores = get_results(score_dir, undesired_subgroups)\n",
    "    tables.append(table)\n",
    "    print(f\"{Fore.LIGHTRED_EX}{score_dir.split('/')[-3].upper()}{Style.RESET_ALL}\")\n",
    "    print(table.get_string(sort_key=operator.itemgetter(1, 0), sortby=\"Domain\"), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2e8cf6c8a0e336b88b8b74ceca74e60238c1300ebcacd360aa408440a347c3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
